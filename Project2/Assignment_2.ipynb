{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjunath-Yelipeta/EVA/blob/master/Project2/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VH1TsnaHz9E",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUfLYIAsRoPs",
        "colab_type": "text"
      },
      "source": [
        "### Installing keras library using pip\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c05a292-cfeb-41e7-aed2-de6a0c4e434a"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFuRYHiTR8bb",
        "colab_type": "text"
      },
      "source": [
        "### importing the libraries and datasets needed for performing convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m-g-IukSHLZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZQWHWk6SKrB",
        "colab_type": "text"
      },
      "source": [
        "###  loading the MNIST data into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e23e0aff-5ad2-440c-9d1a-cd893eba4029"
      },
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9LL2CbkS6S_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFd6js_nS-P1",
        "colab_type": "text"
      },
      "source": [
        "### Checking the shape of training images and plotting the first image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "11a59850-d2ad-4fb2-8854-0860b720334b"
      },
      "source": [
        "\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5874fa2d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypRyTrjgTI5Y",
        "colab_type": "text"
      },
      "source": [
        "### Reshaping the training and test  data into required format for doing convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPPUe7-ATY_p",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNqbIVcfTeH2",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing the data\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSx4zSNpTozk",
        "colab_type": "text"
      },
      "source": [
        "### Printing the first 10 labels of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a398514f-76b5-45d2-d4e4-8ed40587c67b"
      },
      "source": [
        "\n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS2Gywi6T0NC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8mrfwOsT5AB",
        "colab_type": "text"
      },
      "source": [
        "###  Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReH1gUcwVnii",
        "colab_type": "text"
      },
      "source": [
        "### Printing the first ten labels after converting into 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQAdKrYXVuHI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ithZ3ggKVzXX",
        "colab_type": "text"
      },
      "source": [
        "### importing the libraries responsible for transition/bottleneck layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB99tRntV1lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3HV4PZOWBkV",
        "colab_type": "text"
      },
      "source": [
        "### Creating a sequential Neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFBrOQ_bWh6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyVJ94ezWupp",
        "colab_type": "text"
      },
      "source": [
        "### Creating first layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of first layer is (3 * 3).\n",
        "\n",
        "> 2) The input channel dimensions for the first layer is   (28 ,28 ,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asXszGVaYHQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f0ed9356-c6ac-4266-a7ac-fad9d7350cdf"
      },
      "source": [
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqNQ9cayYQk0",
        "colab_type": "text"
      },
      "source": [
        "### Creating second layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of second layer is (5 * 5).\n",
        "\n",
        "> 2) The input channel dimensions for this second layer is         (26, 26, 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DsQw63gY5VU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e42c7be9-3a7d-42ad-88b9-f3cde9f8e23f"
      },
      "source": [
        "model.add(Convolution2D(64, 3, 3, activation='relu'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzJ_qfKNZD0X",
        "colab_type": "text"
      },
      "source": [
        "### Creating third layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of this third layer is (7 * 7).\n",
        "\n",
        "> 2) The input channel dimensions for the third layer is   (24  ,24, 64)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwHtW9lRZZcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8cbebfa9-a917-4e93-fa49-5b661ce998d1"
      },
      "source": [
        "model.add(Convolution2D(128, 3, 3, activation='relu'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrb1tstVZ_EB",
        "colab_type": "text"
      },
      "source": [
        "### Creating maxpooling operation.\n",
        "> 1) The global receptive field for each pixel in the output channels of maxpooling operation  is (14 * 14).\n",
        "\n",
        "> 2) The input channel dimensions for the maxpooling operation  is   (22 ,22,128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuMDri2Ral2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5CFlwyuavhF",
        "colab_type": "text"
      },
      "source": [
        "### Creating fourth layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of this fourth layer is (16 * 16).\n",
        "\n",
        "> 2) The input channel dimensions for the fourth layer is   (11,11 ,128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NxocoQ9bcRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5148292d-6d77-4803-d065-243e7c5e2be1"
      },
      "source": [
        "model.add(Convolution2D(256, 3, 3, activation='relu'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywmaV0M-be9q",
        "colab_type": "text"
      },
      "source": [
        "### Creating fifth layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of this fifth layer is (18 * 18).\n",
        "\n",
        "> 2) The input channel dimensions for the fifth layer is  (9 , 9 , 256)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTubJ2k5ccEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4f567290-2289-48ef-904d-d62800fd08ee"
      },
      "source": [
        "model.add(Convolution2D(512, 3, 3, activation='relu'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL2hkjGCePX2",
        "colab_type": "text"
      },
      "source": [
        "### Creating sixth layer of convolutions.\n",
        "> 1) The global receptive field for each pixel in the output channels of this sixth layer is (20 * 20).\n",
        "\n",
        "> 2) The input channel dimensions for the sixth layer is (7 , 7 , 512)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQaDV8Fetb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c2d6cf8d-1fc0-4f21-a7e9-b506ef900adf"
      },
      "source": [
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVn17VQseyWW",
        "colab_type": "text"
      },
      "source": [
        "### Creating seventh  layer of convolutions.\n",
        "1) The global receptive field for each pixel in the output channels of this seventh layer is (22 * 22).\n",
        "\n",
        "2) The input channel dimensions for the seventh layer is (5 ,5 ,1024)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJytjRknfFlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "da69c132-e93a-4d2f-cf51-c338893fbf1e"
      },
      "source": [
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8oPd9Og7hE",
        "colab_type": "text"
      },
      "source": [
        "### Creating final layer of convolutions.\n",
        "1) The global receptive field for each pixel in the output channels of this final layer is (24 * 24).\n",
        "\n",
        "2) The input channel dimensions for the seventh layer is (3,3,2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egSYpwXXg4cE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHOPXRpWhNis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "abb16b27-b5d6-4eef-fa3d-cd024e4a41a9"
      },
      "source": [
        "model.add(Convolution2D(10, 3, 3, activation='relu'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u2amfoYiQRG",
        "colab_type": "text"
      },
      "source": [
        "### softmax layer expects a 1-D array of scores for each class so flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBpcs1NpjZh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLz1dzrjetP",
        "colab_type": "text"
      },
      "source": [
        "### Adding the softmax activation gives the output of probability like scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuNofD0GjiDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rhgbcagkZ2_",
        "colab_type": "text"
      },
      "source": [
        "### summary function shows the network architecure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f1qcz5TkcNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "69edb013-6f64-4c29-818f-9e6475fc9783"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf5M80V-lKlh",
        "colab_type": "text"
      },
      "source": [
        "## compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKraf-FdlP-N",
        "colab_type": "text"
      },
      "source": [
        "### Training the model with the specified loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "8f2794a8-23c0-450e-b6ea-48fe128f7050"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 120s 2ms/step - loss: 2.0380 - acc: 0.2269\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5871822358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaEnwq9Flgg9",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGrPKISdlkog",
        "colab_type": "text"
      },
      "source": [
        "### Printing the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e90f0610-a4aa-4d11-eb08-9f73a31c0caa"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Ej0lW_los3",
        "colab_type": "text"
      },
      "source": [
        "## Getting model predictions on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "aebab68b-ab11-40f2-87f7-b3a10368bbb5"
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzDV_MZ7yYg8",
        "colab_type": "text"
      },
      "source": [
        "## Wrong with Above Network as per me.\n",
        ">>1)The global receptive field in the above architecture is 24 * 24 which is not equal to the size of the image. As the global receptive field should be equal to size of the image so that condition is not met. So the network can't see the entire Image to classify the image.\n",
        "\n",
        ">> 2)As size of image is not large as it is (28 *28 * 1), we can avoid maxpooling so that the loss of information can be minimized. Max pooling is useful for large sized images to reduce the number of layers which will helpful for large sized Images.\n",
        "\n",
        ">> 3)Activation function Relu not be used in the last convolution layer.\n",
        "\n",
        ">>4) The network should have been designed by keeping the effective receptive field in consideration for edges and gradients,textures, patterns, parts of objects and objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb3AI6-holuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}